---
title: "Decision tree"
---


```{r}
library(tidyverse)
library(rpart)
library(caret)
library(ISLR2)
library(rpart.plot)
```

```{r}
data <- read.csv("C:\\study_performance_simple.csv")
```


```{r}
set.seed(123)
sample_index <- sample(c(TRUE, FALSE), nrow(data), replace = TRUE, prob = c(0.8, 0.2))

train_data <- data[sample_index, ]
test_data <- data[!sample_index, ] 

cat("Training set observations:", nrow(train_data), "\n")
cat("Test set observations:", nrow(test_data), "\n")

```


```{r}
reg_tree <- rpart(math_score ~ gender + race_ethnicity + parental_level_of_education + lunch + test_preparation_course,
                  data = train_data, method = "anova", cp = 0.008)
```


```{r}
rpart.plot(reg_tree)
```

```{r}
tree_predictions <- predict(reg_tree, newdata = test_data)
head(tree_predictions, 6)
```


```{r}
results <- tibble(
  actual = test_data$math_score,
  predicted = tree_predictions
)
results
```

```{r}
rmse <- sqrt(mean((results$actual - results$predicted)^2))

cat("RMSE of the decision tree model:", rmse, "\n")
```


```{r}

multi_reg_model <- rpart(math_score ~ gender + race_ethnicity + parental_level_of_education + lunch + test_preparation_course,
                         data = train_data, method = "anova", cp = 0)

```


```{r}
rpart.plot(multi_reg_model)
```

  
```{r}

multi_reg_predictions <- predict(multi_reg_model, newdata = test_data)

head(multi_reg_predictions, 6)
```

```{r}
multi_reg_results <- tibble(
  actual = test_data$math_score,
  predicted = multi_reg_predictions
)
multi_reg_rmse <- sqrt(mean((multi_reg_results$actual - multi_reg_results$predicted)^2))

cat("RMSE of the multiple regression model:", multi_reg_rmse, "\n")
```

  
```{r}
data_class <- data %>%
  mutate(pass = ifelse(math_score > 65, "Yes", "No")) %>%
  select(-math_score)

head(data_class)
```


```{r}
set.seed(123)
sample_index <- sample(c(TRUE, FALSE), nrow(data_class), replace = TRUE, prob = c(0.8, 0.2))
train_data_class <- data_class[sample_index, ]
test_data_class <- data_class[!sample_index, ]

cat("Training set observations:", nrow(train_data_class), "\n")
cat("Test set observations:", nrow(test_data_class), "\n")

```


```{r}
class_tree <- rpart(pass ~ gender + race_ethnicity + parental_level_of_education + lunch + test_preparation_course,
                    data = train_data_class, method = "class", cp = 0.008)
```

```{r}
rpart.plot(class_tree)
```


```{r}
class_predictions <- predict(class_tree, newdata = test_data_class, type = "class")
head(class_predictions, 6)
```


```{r}

class_predictions_tibble <- tibble(
  truth = factor(test_data_class$pass),
  pred = factor(class_predictions, levels = levels(factor(test_data_class$pass)))
)

class_predictions_tibble
```

```{r}
conf_matrix <- confusionMatrix(data = class_predictions_tibble$pred, reference = class_predictions_tibble$truth)
conf_matrix
```

Report the following metrics:

- What is the accuracy?
```{r}
cat("Accuracy:", conf_matrix$overall['Accuracy'], "\n")

```
Answer : 0.6313131 

- What is false positive rate?
```{r}
FPR <- conf_matrix$byClass['Specificity']
cat("False Positive Rate (FPR):", 1 - FPR, "\n")

```
Answer: FPR <- FP / (FP + TN)
FPR = 28/(28+77) = 0.2666


- What is true positive rate?
```{r}
TPR <- conf_matrix$byClass['Sensitivity']
cat("True Positive Rate (TPR):", TPR, "\n")

```
Answer :TPR <- TP / (TP + FN)
TPR = 48/(48+45) = 0.5161

```{r}

train_data_class <- train_data_class %>%
  mutate(pass_binary = ifelse(pass == "Yes", 1, 0))

test_data_class <- test_data_class %>%
  mutate(pass_binary = ifelse(pass == "Yes", 1, 0))

## Build a logistic regression model
logistic_model <- glm(pass_binary ~ gender + race_ethnicity + parental_level_of_education + lunch + test_preparation_course,
                      data = train_data_class, family = "binomial")

summary(logistic_model)

```


```{r}
logistic_predictions_prob <- predict(logistic_model, newdata = test_data_class, type = "response")
head(logistic_predictions_prob, 6)

```


```{r}
logistic_predictions_class <- ifelse(logistic_predictions_prob > 0.5, "Yes", "No")
head(logistic_predictions_class, 6)
```
```{r}

logistic_predictions_tibble <- tibble(
  truth = factor(test_data_class$pass),
  pred = factor(logistic_predictions_class, levels = levels(factor(test_data_class$pass)))
)

conf_matrix_logistic <- confusionMatrix(data = logistic_predictions_tibble$pred, reference = logistic_predictions_tibble$truth)
conf_matrix_logistic

```
Report the following metrics:

- What is the accuracy?
Accuracy : 0.6616
```{r}

cat("Accuracy:", conf_matrix_logistic$overall['Accuracy'], "\n")

```
- What is false positive rate?
```{r}

FPR_logistic <- conf_matrix_logistic$byClass['Specificity']
cat("False Positive Rate (FPR):", 1 - FPR_logistic, "\n")

```
Answer :TPR <- FP / (FP + TN)
TPR = 35 / (35+70) = 0.3333

- What is true positive rate?
```{r}

TPR_logistic <- conf_matrix_logistic$byClass['Sensitivity']
cat("True Positive Rate (TPR):", TPR_logistic, "\n")

```
Answer :
Answer :TPR <- TP / (TP + FN)
TPR = 61/(61+32) = 0.6559
