---
title: "Logistic regression"
---

```{r}
library(tidyverse)
library(caret)
library(pROC)
```

  
```{r}
# Load the data
ca_school <- read_csv("CA_school_pass.csv")

# Examine the data
glimpse(ca_school)

# Number of rows and columns
cat("Number of rows:", nrow(ca_school), "\n")
cat("Number of columns:", ncol(ca_school), "\n")

# Column names and types
str(ca_school)
```


```{r}
ca_school <- ca_school %>%
  mutate(pass = factor(pass, levels = c("No", "Yes")))
```



```{r}
set.seed(23)

# Create index for splitting
split_index <- createDataPartition(ca_school$pass, p = 0.8, list = FALSE)

# Create training and test sets
train_set <- ca_school[split_index, ]
test_set <- ca_school[-split_index, ]
```



```{r}
cat("Number of rows in training set:", nrow(train_set), "\n")
cat("Number of rows in test set:", nrow(test_set), "\n")
```


```{r}
model1 <- glm(pass ~ computer, data = train_set, family = "binomial")
summary(model1)
```


```{r}
ggplot(train_set, aes(x = computer, y = as.numeric(pass) - 1)) +
  geom_point(alpha = 0.5) +
  stat_smooth(method = "glm", method.args = list(family = "binomial"), se = FALSE) +
  labs(x = "Computer", y = "Probability of Pass") +
  theme_minimal()
```



```{r}
predictions_model1 <- predict(model1, newdata = test_set, type = "response")
head(predictions_model1)
```


```{r}
predicted_classes_model1 <- ifelse(predictions_model1 > 0.5, "Yes", "No")
conf_matrix_model1 <- confusionMatrix(factor(predicted_classes_model1), test_set$pass)
conf_matrix_model1
```

```{r}
cat("Accuracy of Model 1:", conf_matrix_model1$overall["Accuracy"], "\n")
```


```{r}
roc_model1 <- roc(test_set$pass, predictions_model1)
auc_model1 <- auc(roc_model1)
cat("AUC for Model 1:", auc_model1, "\n")
```


```{r}
model2 <- glm(pass ~ teachers + mealpct + computer + avginc, data = train_set, family = "binomial")
summary(model2)
```



```{r}
predictions_model2 <- predict(model2, newdata = test_set, type = "response")
head(predictions_model2)
```


```{r}
predicted_classes_model2 <- ifelse(predictions_model2 > 0.5, "Yes", "No")
conf_matrix_model2 <- confusionMatrix(factor(predicted_classes_model2), test_set$pass)
conf_matrix_model2
```

```{r}
cat("Accuracy of Model 2:", conf_matrix_model2$overall["Accuracy"], "\n")
```

```{r}
roc_model2 <- roc(test_set$pass, predictions_model2)
auc_model2 <- auc(roc_model2)
cat("AUC for Model 2:", auc_model2, "\n")
```


```{r}
plot(roc_model2, main = "ROC Curve for Model 2")
```

